# llm_config.py
LLM_CONFIG = {
    "gpt-4o-mini": {
        "family": "openai",
        "model": "gpt-4o-mini",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "supports_image": False,
        "price_input_token_1M": 0.15,
        "price_output_token_1M": 0.60
    },
    "gpt-4.1": {
        "family": "openai",
        "model": "gpt-4.1",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "supports_image": True,
        "price_input_token_1M": 2,
        "price_output_token_1M": 8
    },
    "gpt-4.1-mini": {
        "family": "openai",
        "model": "gpt-4.1-mini",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "supports_image": True,
        "price_input_token_1M": .4,
        "price_output_token_1M": 1.6
    },
    "rag-with-gpt-4o": {
        "family": "rag",
        "model": "gpt-4-turbo",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "supports_image": True,
        "price_input_token_1M": 10,
        "price_output_token_1M": 30
    },
    "gpt-4o": {
        "family": "openai",
        "model": "gpt-4o",
        "max_tokens": 2000,
        "temperature": 1.0,
        "top_p": 1.0,
        "supports_image": True,
        "price_input_token_1M": 2.5,
        "price_output_token_1M": 10
    },
    "gemini-pro": {
        "family": "gemini",
        "model": "gemini-pro",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 0.95,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 2.5,
        "price_output_token_1M": 10.00
    },
    "gemini-pro-vision": {
        "family": "gemini",
        "model": "gemini-pro-vision",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 0.95,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": True,
        "price_input_token_1M": 0.15,
        "price_output_token_1M": 0.60
    },
    "claude-3.5-sonnet": {
        "family": "claude",
        "model": "claude-3-5-sonnet-latest",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": True,
        "price_input_token_1M": 3,
        "price_output_token_1M": 15
    },
    "claude-opus": {
        "family": "claude",
        "model": "claude-3-opus-latest",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": True,
        "price_input_token_1M": 15,
        "price_output_token_1M": 75
    },
    "claude-3.5-haiku": {
        "family": "claude",
        "model": "claude-3-5-haiku-latest",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 1,
        "price_output_token_1M": 5
    },
    "llama-3.1-sonar-small-128k-chat": {
        "family": "perplexity",
        "model": "llama-3.1-sonar-small-128k-chat",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 0.20,
        "price_output_token_1M": 0.20
    },
    "llama-3.1-sonar-small-128k-online": {
        "family": "perplexity",
        "model": "llama-3.1-sonar-small-128k-online",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 0.20,
        "price_output_token_1M": 0.20
    },
    "llama-3.1-sonar-large-128k-chat": {
        "family": "perplexity",
        "model": "llama-3.1-sonar-large-128k-chat",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 1.0,
        "price_output_token_1M": 1.0
    },
    "llama-3.1-sonar-large-128k-online": {
        "family": "perplexity",
        "model": "llama-3.1-sonar-large-128k-online",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 1.0,
        "price_output_token_1M": 1.0
    },
    "llama-3.1-8b-instruct": {
        "family": "perplexity",
        "model": "llama-3.1-8b-instruct",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 0.20,
        "price_output_token_1M": 0.20
    },
    "llama-3.1-70b-instruct": {
        "family": "perplexity",
        "model": "llama-3.1-70b-instruct",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 1.0,
        "price_output_token_1M": 1.0
    }
}
