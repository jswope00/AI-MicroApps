# llm_config.py
LLM_CONFIG = {
    "gpt-4o-mini": {
        "family": "openai",
        "model": "gpt-4o-mini",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 0.15,
        "price_output_token_1M": 0.60
    },
    "gpt-4-turbo": {
        "family": "openai",
        "model": "gpt-4-turbo",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": True,
        "price_input_token_1M": 10,
        "price_output_token_1M": 30
    },
    "rag-with-gpt-4o": {
        "family": "rag",
        "model": "gpt-4-turbo",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": True,
        "price_input_token_1M": 10,
        "price_output_token_1M": 30
    },
    "gpt-4o": {
        "family": "openai",
        "model": "gpt-4o",
        "max_tokens": 2000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": True,
        "price_input_token_1M": 5,
        "price_output_token_1M": 15
    },
    "gemini-1.5-flash": {
        "family": "gemini",
        "model": "gemini-1.5-flash",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 0.95,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 0.35,
        "price_output_token_1M": 1.05
    },
    "gemini-1.5-pro": {
        "family": "gemini",
        "model": "gemini-1.5-pro",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 0.95,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": True,
        "price_input_token_1M": 3.5,
        "price_output_token_1M": 10.50
    },
    "claude-3.5-sonnet": {
        "family": "claude",
        "model": "claude-3-5-sonnet-20240620",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": True,
        "price_input_token_1M": 3,
        "price_output_token_1M": 15
    },
    "claude-opus": {
        "family": "claude",
        "model": "claude-3-opus-20240229",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": True,
        "price_input_token_1M": 15,
        "price_output_token_1M": 75
    },
    "claude-sonnet": {
        "family": "claude",
        "model": "claude-3-sonnet-20240229",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": True,
        "price_input_token_1M": 3,
        "price_output_token_1M": 15
    },
    "claude-haiku": {
        "family": "claude",
        "model": "claude-3-haiku-20240307",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 0.25,
        "price_output_token_1M": 1.25
    },
    "llama-3.1-sonar-small-128k-chat": {
        "family": "perplexity",
        "model": "llama-3.1-sonar-small-128k-chat",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 0.20,
        "price_output_token_1M": 0.20
    },
    "llama-3.1-sonar-small-128k-online": {
        "family": "perplexity",
        "model": "llama-3.1-sonar-small-128k-online",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 0.20,
        "price_output_token_1M": 0.20
    },
    "llama-3.1-sonar-large-128k-chat": {
        "family": "perplexity",
        "model": "llama-3.1-sonar-large-128k-chat",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 1.0,
        "price_output_token_1M": 1.0
    },
    "llama-3.1-sonar-large-128k-online": {
        "family": "perplexity",
        "model": "llama-3.1-sonar-large-128k-online",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 1.0,
        "price_output_token_1M": 1.0
    },
    "llama-3.1-8b-instruct": {
        "family": "perplexity",
        "model": "llama-3.1-8b-instruct",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 0.20,
        "price_output_token_1M": 0.20
    },
    "llama-3.1-70b-instruct": {
        "family": "perplexity",
        "model": "llama-3.1-70b-instruct",
        "max_tokens": 1000,
        "temperature": 1.0,
        "top_p": 1.0,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "supports_image": False,
        "price_input_token_1M": 1.0,
        "price_output_token_1M": 1.0
    }
}
